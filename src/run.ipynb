{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e79688",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import gymnasium as gym\n",
    "from agents.generator import Generator\n",
    "from agents.reflector import Reflector\n",
    "from agents.curator import Curator\n",
    "from environments.FrozenLake import FrozenLake\n",
    "from prompts.FrozenLakePrompt import FrozenLakePrompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2866a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = True\n",
    "max_iterations = 3\n",
    "# Pipeline Setup\n",
    "client = OpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key= os.getenv(\"OPENROUTER_API_KEY\")\n",
    ") \n",
    "custom_map = [\n",
    "    \"SFFF\",\n",
    "    \"FFFH\",\n",
    "    \"HFFH\",\n",
    "    \"FHFF\",\n",
    "    \"FFFG\"\n",
    "]\n",
    "model = \"x-ai/grok-4-fast\"\n",
    "FrozenLakeGame = FrozenLake(env = gym.make(\"FrozenLake-v1\",\n",
    "                      render_mode=\"ansi\", \n",
    "                      desc=custom_map,\n",
    "                      map_name=None,\n",
    "                      is_slippery=True,\n",
    "                      success_rate=0.66,\n",
    "                      reward_schedule=(1, 0, 0)))\n",
    "\n",
    "# TODO: Update Refelecotr + Curator Prompts with Ground Truth\n",
    "playbook = \"\"\n",
    "reflection = \"\"\n",
    "prompt = FrozenLakePrompt(playbook=playbook, reflection=reflection)\n",
    "\n",
    "for i in range(max_iterations):\n",
    "    FrozenLakeGame.reset() \n",
    "    if DEBUG:\n",
    "        print(f\"===== Iteration {i+1} =====\")\n",
    "        print(\"=== Playbook ===\")\n",
    "        print(prompt.getPlaybookAsString())\n",
    "        print(\"================\")\n",
    "\n",
    "\n",
    "    # Generator Setup\n",
    "    if DEBUG:\n",
    "        print(f\"===== Generator Run =====\")\n",
    "         \n",
    "    model = \"x-ai/grok-4-fast\"\n",
    "    generatorLake = Generator(client, model, FrozenLakeGame, prompt=prompt)\n",
    "    generatorOutput, step = generatorLake.run(debug=DEBUG)\n",
    "    prompt.setGeneratorOutput(generatorOutput)\n",
    "    \n",
    "    if DEBUG:\n",
    "        print(\"=======================\")\n",
    "\n",
    "\n",
    "    # Reflector Setup; Possible Iteration: Gen Traces -> Reflector Insights -> Gen Traces -> Improved Reflector Insights -> etc.\n",
    "    if DEBUG:\n",
    "        print(f\"=== Reflector Run ===\")\n",
    "        print(f\"== Prompt: {prompt.getReflectorPrompt()}\")\n",
    "    \n",
    "    model = \"openai/gpt-4o\"\n",
    "    reflectorLake = Reflector(client, model, prompt)\n",
    "    reflection = reflectorLake.run(debug=DEBUG)\n",
    "    prompt.setReflection(reflection)\n",
    "    \n",
    "    if DEBUG:\n",
    "        print(\"========================\")\n",
    "\n",
    "\n",
    "    # Curator Setup: TODO: Add Metadata: Count how often bulletpoint was marked helpful or harmful\n",
    "    if DEBUG:\n",
    "        print(f\"=== Curator Run ===\")\n",
    "        print(f\"== Prompt: {prompt.getCuratorPrompt()}\")\n",
    "    \n",
    "    model = \"x-ai/grok-4-fast\"\n",
    "    curatorLake = Curator(client, model, prompt)\n",
    "    curatorLake.run(debug=DEBUG) # updates playbook\n",
    "    prompt.refreshPlaybook()   \n",
    "    \n",
    "    if DEBUG:\n",
    "        print(\"=======================\")\n",
    "        print(f\"=== End of Iteration {i+1} ===\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
